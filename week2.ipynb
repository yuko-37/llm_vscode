{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d57306d7-7a8f-43c4-ba96-d531bcc48fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "635f5072-9a9d-405f-9b68-9d7b53a0412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyCd\n",
      "Deepseek API Key exists and begins sk-5a19f\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"Deepseek API Key exists and begins {deepseek_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "084da8fe-9a73-4002-886d-c0bc748ba9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = 'You are assistant that is great at telling jokes'\n",
    "user_prompt = 'Tell a light-hearted joke to an audience of Data Scientists'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886e11af-ffd1-4d58-81cc-e14a8846560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {'role': 'system', 'content': system_message},\n",
    "    {'role': 'user', 'content': user_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "493c9e70-c1e8-4d62-922f-68469ad4aee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with their computer? \n",
      "\n",
      "They couldn't handle their data-driven relationship!\n"
     ]
    }
   ],
   "source": [
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-3.5-turbo', messages=prompts\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1038d277-eb8e-4d88-b63a-50e8ab993229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist bring a ladder to work?\n",
      "\n",
      "Because they wanted to reach new heights in their analysis!\n"
     ]
    }
   ],
   "source": [
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.4\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "596a78f6-7851-48ac-a718-b4a8b5e079b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = anthropic.Anthropic(\n",
    "    api_key=anthropic_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22cf0c4d-aedc-4166-ac37-8221da1207cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a light-hearted joke for data scientists:\n",
      "\n",
      "Why did the data scientist bring a ladder to work?\n",
      "\n",
      "To climb to the top of the bell curve!\n",
      "\n",
      "This joke plays on the concept of the bell curve (or normal distribution) that's commonly used in statistics and data analysis. The idea of physically climbing to the top of it adds a silly, visual element that data scientists might appreciate. It's a harmless pun that combines a everyday object (a ladder) with a statistical concept in a unexpected way.\n"
     ]
    }
   ],
   "source": [
    "message = claude.messages.create(\n",
    "    model='claude-3-5-sonnet-20240620',\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': user_prompt}\n",
    "    ]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b51c0492-3570-4641-9c91-8d83d9b12202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a light-hearted joke for an audience of Data Scientists:\n",
      "\n",
      "Why do data scientists prefer dark mode?\n",
      "\n",
      "Because light attracts bugs!\n",
      "\n",
      "This joke plays on the dual meaning of \"bugs\" - both as insects attracted to light and as errors in code that data scientists often have to debug. It's a fun way to combine a common tech preference (dark mode) with a data science-related pun.\n",
      "\n",
      "\n",
      "\n",
      "Sure, here's a light-hearted joke for an audience of Data Scientists:\n",
      "\n",
      "Why do data scientists prefer dark mode?\n",
      "\n",
      "Because light attracts bugs!\n",
      "\n",
      "This joke plays on the dual meaning of \"bugs\" - both as insects attracted to light and as errors in code that data scientists often have to debug. It's a fun way to combine a common tech preference (dark mode) with a data science-related pun.\n"
     ]
    }
   ],
   "source": [
    "result = claude.messages.stream(\n",
    "    model='claude-3-5-sonnet-20240620',\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "reply = ''\n",
    "with result as stream:\n",
    "    for text in stream.text_stream:\n",
    "        reply += text or ''\n",
    "\n",
    "print(reply)\n",
    "complete_response = stream.get_final_message()\n",
    "print('\\n\\n')\n",
    "print(complete_response.content[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68e6b147-3583-4e6e-8368-2b2559fd94e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the data scientist sad?  Because he didn't get any arrays!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=google_api_key)\n",
    "gemini = genai.GenerativeModel(\n",
    "    model_name='gemini-1.5-flash',\n",
    "    system_instruction=system_message\n",
    ")\n",
    "response = gemini.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7dae77e4-2dbc-42f0-97a5-8259d91ae331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do data scientists enjoy nature hikes?\n",
      "\n",
      "Because they're always looking for the path with the least resistance and the most significant results!\n"
     ]
    }
   ],
   "source": [
    "stream = openai.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "reply = ''\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "\n",
    "print(reply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1cfcb8e6-39b8-4909-8f08-7bb5839d7b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hereâ€™s a light-hearted joke for your data scientist audience:\n",
       "\n",
       "**Why did the data scientist bring a ladder to the bar?**\n",
       "\n",
       "*Because they heard the drinks were on the houseâ€¦ and they wanted to optimize their access to the top shelf!*  \n",
       "\n",
       "*(Bonus groan-worthy follow-up: \"But then they realized it was just an overfit model of the menu.\")*  \n",
       "\n",
       "Hope it gets a chuckle (or at least an appreciative sigh)! ðŸ˜„"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deepseek = openai.OpenAI(\n",
    "    api_key=deepseek_api_key,\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "response = deepseek.chat.completions.create(\n",
    "    model='deepseek-chat',\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': system_message},\n",
    "        {'role': 'user', 'content': user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "reply = response.choices[0].message.content\n",
    "\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "update_display(Markdown(reply), display_id=display_handle.display_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f99ced7-001f-48c7-8083-0b59bc841a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
