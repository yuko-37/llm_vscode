{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aadcf78a-7db0-45ef-8d61-6efa880c9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45636867-bcec-4281-9910-1134036840b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1088, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created: 123\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "documents = []\n",
    "\n",
    "folders = Path(\".\").glob(\"knowledge-base/*\")\n",
    "for folder in folders:\n",
    "    if folder.is_dir():\n",
    "        loader = DirectoryLoader(folder, loader_cls = TextLoader)\n",
    "        docs = loader.load()\n",
    "        documents += docs\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(documents)\n",
    "print(f\"Chunks created: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e28eec-bc6b-46cc-a998-3c5668a23dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 123 documents.\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "db_name = \"vector_db\"\n",
    "db_path = Path(db_name)\n",
    "\n",
    "if db_path.exists():\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(chunks, persist_directory=db_name, embedding=embeddings)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd2017-9057-45ca-9c1c-0105cc6e2845",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain_ollama\n",
    "!pip install -U langchain_core.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7236075-eba7-49a4-8e38-30e5c3866d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core.messages\n",
    "dir (langchain_core.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420b7a2-c153-4a82-887c-d6e13a2b2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad07290-5b8e-4857-9634-e39c03d9f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_embeddings = OllamaEmbeddings(model=\"ollama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a08f8b18-cfef-48af-8e94-dd778b304880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ny/bjrptr9d4f9c3mmxj10zzcl40000gp/T/ipykernel_49135/859997501.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-5\")\n",
    "retriever = vectorstore.as_retriever()\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3386823-46e2-4c98-bc51-aac94a10ec7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avery Lancaster is the Co-Founder and CEO of Insurellm, based in San Francisco. She co-founded the company in 2015 and has led its growth into a leading insurance tech provider, known for innovative leadership and risk management. Previously, she was a Senior Product Manager at Innovate Insurance Solutions (2013â€“2015), and she champions diversity, flexible work, and community financial literacy initiatives.\n"
     ]
    }
   ],
   "source": [
    "resp = chain.invoke({\"question\": \"Who is Lancaster?\"})\n",
    "print(resp[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51352e13-8176-48c1-8a9a-505b123ac219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def chat(message, history):\n",
    "    resp = chain.invoke({\"question\": message})\n",
    "    return resp[\"answer\"]\n",
    "\n",
    "ui = gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f23336-4eec-4b0b-85ab-24bf07bf42cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
