{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f06970-2de5-43bd-bc09-83219eabce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing import List, TypedDict\n",
    "from langgraph.graph import StateGraph, MessagesState, END\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa971bb-5c76-41f2-a0d9-98f884e83850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c01b03e6-9ac2-4c82-a3a6-9782d45ca724",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "# vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d6545f6-1600-48c6-bb2d-09b26e476ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 1 docs created 63 chunks.\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "print(f\"From {len(docs)} docs created {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfd6d497-1f14-4ea9-b284-c5bbc05c026d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create VectorStore with 63\n"
     ]
    }
   ],
   "source": [
    "vectorstore = InMemoryVectorStore.from_documents(chunks, embeddings)\n",
    "print(f\"Create VectorStore with {len(vectorstore.store.items())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fdabf143-d638-4654-9397-7199eea6fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vectorstore.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join((f\"Source: {doc.metadata}\\nContent: {doc.page_content}\") for doc in retrieved_docs)\n",
    "    return serialized, retrieved_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d6105ea7-0a1a-4068-a662-0abadac2372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_or_respond(state: MessagesState):\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "def generate(state: MessagesState):\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "\n",
    "    conversation_messages = [\n",
    "        message for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b2e6d320-205e-42cd-8697-faf7f7d9b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(MessagesState)\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f55c60-3ad8-486c-ad84-1fc57b82e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"What is Task Decomposition?\"\n",
    "resp = graph.invoke({\"messages\": [{'role': 'user', 'content': input}]}, config=config)\n",
    "# print(resp['messages'][-1].pretty_print())\n",
    "print(resp['messages'][-1].content)\n",
    "\n",
    "input = \"Could you look up some common way of doing it?\"\n",
    "resp = graph.invoke({\"messages\": [{'role': 'user', 'content': input}]}, config=config)\n",
    "print(resp['messages'][-1].pretty_print())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c458d63-5d8a-48aa-8c7e-4777534fd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in graph.stream(\n",
    "    {\"messages\": [{'role': 'user', 'content': input}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27735443-2836-45d8-aa1c-595392c91bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Could you look up some common way of doing it?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{'role': 'user', 'content': input}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "66943678-b301-4764-a03b-b9df2ba6ae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def chat(message, history):\n",
    "    resp = graph.invoke({\"messages\": [{\"role\": 'user', 'content': message}]}, config=config)\n",
    "    return resp[\"messages\"][-1].content\n",
    "\n",
    "ui = gr.ChatInterface(fn=chat, type=\"messages\")\n",
    "ui.launch(inbrowser=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f182dc-9bef-4657-b61e-ad83f41d4a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
