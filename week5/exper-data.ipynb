{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610c0cd-f88c-472e-9a16-9ea5f9e8f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"unstructured[epub]\" langchain-community\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa6af9c1-2c5c-4e14-b869-3deae1d4ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader, UnstructuredEPubLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed9aed8-5fba-4659-9837-e37333656bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f74271-ddfb-4874-b78d-fd8717b401ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "2\n",
      "215\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(file_path=\"experiment-data/Dale Carnegie.pdf\")\n",
    "pages = loader.load()\n",
    "for page in pages:\n",
    "    page.metadata[\"type\"] = \"Dale Carnegie\"\n",
    "print(len(pages))\n",
    "\n",
    "folder = Path(\"experiment-data\")\n",
    "dir_loader = DirectoryLoader(folder, glob=\"*.epub\", loader_cls=UnstructuredEPubLoader)\n",
    "epub_docs = dir_loader.load()\n",
    "\n",
    "pattern = re.compile(\"(.+)/(.+)(\\..+).epub$\")\n",
    "\n",
    "for e_doc in epub_docs:\n",
    "    source = e_doc.metadata[\"source\"]\n",
    "    match = pattern.match(source)\n",
    "    doc_type = match.group(2)\n",
    "    e_doc.metadata[\"type\"] = doc_type\n",
    "\n",
    "print(len(epub_docs))\n",
    "\n",
    "documents = []\n",
    "documents += pages\n",
    "documents += epub_docs\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81569b82-e98e-44e5-82ad-a67ad0ca93ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1692, which is longer than the specified 1000\n",
      "Created a chunk of size 1530, which is longer than the specified 1000\n",
      "Created a chunk of size 1087, which is longer than the specified 1000\n",
      "Created a chunk of size 1062, which is longer than the specified 1000\n",
      "Created a chunk of size 1139, which is longer than the specified 1000\n",
      "Created a chunk of size 1093, which is longer than the specified 1000\n",
      "Created a chunk of size 1068, which is longer than the specified 1000\n",
      "Created a chunk of size 1229, which is longer than the specified 1000\n",
      "Created a chunk of size 1113, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1174, which is longer than the specified 1000\n",
      "Created a chunk of size 1832, which is longer than the specified 1000\n",
      "Created a chunk of size 1991, which is longer than the specified 1000\n",
      "Created a chunk of size 1020, which is longer than the specified 1000\n",
      "Created a chunk of size 1418, which is longer than the specified 1000\n",
      "Created a chunk of size 1537, which is longer than the specified 1000\n",
      "Created a chunk of size 1066, which is longer than the specified 1000\n",
      "Created a chunk of size 1551, which is longer than the specified 1000\n",
      "Created a chunk of size 1008, which is longer than the specified 1000\n",
      "Created a chunk of size 1057, which is longer than the specified 1000\n",
      "Created a chunk of size 1131, which is longer than the specified 1000\n",
      "Created a chunk of size 1020, which is longer than the specified 1000\n",
      "Created a chunk of size 1088, which is longer than the specified 1000\n",
      "Created a chunk of size 1071, which is longer than the specified 1000\n",
      "Created a chunk of size 1022, which is longer than the specified 1000\n",
      "Created a chunk of size 1202, which is longer than the specified 1000\n",
      "Created a chunk of size 1070, which is longer than the specified 1000\n",
      "Created a chunk of size 1011, which is longer than the specified 1000\n",
      "Created a chunk of size 1022, which is longer than the specified 1000\n",
      "Created a chunk of size 1247, which is longer than the specified 1000\n",
      "Created a chunk of size 1120, which is longer than the specified 1000\n",
      "Created a chunk of size 1091, which is longer than the specified 1000\n",
      "Created a chunk of size 1008, which is longer than the specified 1000\n",
      "Created a chunk of size 1008, which is longer than the specified 1000\n",
      "Created a chunk of size 1071, which is longer than the specified 1000\n",
      "Created a chunk of size 1105, which is longer than the specified 1000\n",
      "Created a chunk of size 1325, which is longer than the specified 1000\n",
      "Created a chunk of size 1052, which is longer than the specified 1000\n",
      "Created a chunk of size 1033, which is longer than the specified 1000\n",
      "Created a chunk of size 1009, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1308, which is longer than the specified 1000\n",
      "Created a chunk of size 1082, which is longer than the specified 1000\n",
      "Created a chunk of size 1009, which is longer than the specified 1000\n",
      "Created a chunk of size 1189, which is longer than the specified 1000\n",
      "Created a chunk of size 1016, which is longer than the specified 1000\n",
      "Created a chunk of size 1096, which is longer than the specified 1000\n",
      "Created a chunk of size 1025, which is longer than the specified 1000\n",
      "Created a chunk of size 1082, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1019, which is longer than the specified 1000\n",
      "Created a chunk of size 1079, which is longer than the specified 1000\n",
      "Created a chunk of size 1054, which is longer than the specified 1000\n",
      "Created a chunk of size 1071, which is longer than the specified 1000\n",
      "Created a chunk of size 1082, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n",
      "Created a chunk of size 1138, which is longer than the specified 1000\n",
      "Created a chunk of size 1062, which is longer than the specified 1000\n",
      "Created a chunk of size 1272, which is longer than the specified 1000\n",
      "Created a chunk of size 1131, which is longer than the specified 1000\n",
      "Created a chunk of size 1311, which is longer than the specified 1000\n",
      "Created a chunk of size 1027, which is longer than the specified 1000\n",
      "Created a chunk of size 1031, which is longer than the specified 1000\n",
      "Created a chunk of size 1076, which is longer than the specified 1000\n",
      "Created a chunk of size 1199, which is longer than the specified 1000\n",
      "Created a chunk of size 1052, which is longer than the specified 1000\n",
      "Created a chunk of size 1241, which is longer than the specified 1000\n",
      "Created a chunk of size 1012, which is longer than the specified 1000\n",
      "Created a chunk of size 1337, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1403, which is longer than the specified 1000\n",
      "Created a chunk of size 1160, which is longer than the specified 1000\n",
      "Created a chunk of size 1093, which is longer than the specified 1000\n",
      "Created a chunk of size 1238, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n",
      "Created a chunk of size 1029, which is longer than the specified 1000\n",
      "Created a chunk of size 1128, which is longer than the specified 1000\n",
      "Created a chunk of size 1459, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3996\n"
     ]
    }
   ],
   "source": [
    "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(documents)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9012493-1835-4ae2-b842-81db641fe5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", )\n",
    "db_name = \"experiment_db\"\n",
    "db_path = Path(db_name)\n",
    "\n",
    "if db_path.exists():\n",
    "    shutil.rmtree(db_path, ignore_errors=True)\n",
    "    Chroma(embedding_function=embeddings, persist_directory=db_name).delete_collection()\n",
    "\n",
    "store = Chroma(persist_directory=db_name, embedding_function=embeddings)\n",
    "print(f\"Vector storage {db_name} is created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5201606-d8d9-41dd-9603-02c57cfae952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(docs, size):\n",
    "    for i in range(0, len(docs), size):\n",
    "        yield docs[i:i+size]\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "for batch in get_batch(chunks, batch_size):\n",
    "    store.add_documents(batch)\n",
    "\n",
    "print(f\"{store._collection.count()} docs have been added to vector store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "637d4e4d-8684-40b6-8e01-467d9e0bbba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = store.get(include=[\"embeddings\", \"documents\", \"metadatas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0a7308e-9971-4e3c-87d0-1339f482ba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3996, 3072)\n",
      "(3072,)\n"
     ]
    }
   ],
   "source": [
    "vectors = np.array(data[\"embeddings\"])\n",
    "print(vectors.shape)\n",
    "print(vectors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8de16f0e-b184-4323-852c-a58276765b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Published in 1937. \n",
      " \n",
      "Th\n"
     ]
    }
   ],
   "source": [
    "documents = data[\"documents\"]\n",
    "print(documents[1][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeb440b6-fd3f-4a6b-a83a-9905541224a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "975b8ddb-9ce2-45cb-ac7e-baea515e5a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3996, 2)\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, random_state=37)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "print(reduced_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80d84181-3a80-4690-b323-1ec37bdd56db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Уопник Кеннет', 'Dale Carnegie', 'Тит Хань'}\n"
     ]
    }
   ],
   "source": [
    "types = [md[\"type\"] for md in data[\"metadatas\"]]\n",
    "type_set = set(types)\n",
    "print(type_set)\n",
    "type_list = list(type_set)\n",
    "\n",
    "texts = [f\"Type: {t}<br>Text: {doc[:100]}\" for doc, t in zip(documents, types)]\n",
    "\n",
    "color_list = [\"blue\", \"red\", \"green\"]\n",
    "colors = [color_list[type_list.index(t)] for t in types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e377051a-0712-4795-9c56-d65fd2a6e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scattered_data = go.Scatter(\n",
    "    x = reduced_vectors[:,0],\n",
    "    y = reduced_vectors[:,1],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=5, color=colors, opacity=1),\n",
    "    text=texts,\n",
    "    hoverinfo=\"text\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[scattered_data])\n",
    "fig.update_layout(\n",
    "    title = \"2D Experiment Vector Store Visualization\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, l=10, b=10, t=40)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2120a5-89b3-45cc-9610-00c65dd976da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3, random_state=37)\n",
    "reduced_vectors = tsne.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96aed5-d814-4158-be74-671f645aef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scattered_data = go.Scatter3d(\n",
    "    x = reduced_vectors[:,0],\n",
    "    y = reduced_vectors[:,1],\n",
    "    z = reduced_vectors[:,2],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=5, color=colors, opacity=1),\n",
    "    text=texts,\n",
    "    hoverinfo=\"text\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[scattered_data])\n",
    "fig.update_layout(\n",
    "    title = \"3D Experiment Vector Store Visualization\",\n",
    "    width=1600,\n",
    "    height=1000,\n",
    "    margin=dict(r=20, l=10, b=10, t=40)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059226c-7ce4-4d0f-a7ba-340e94ec94ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
