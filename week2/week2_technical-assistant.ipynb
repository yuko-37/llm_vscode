{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5745680d-7661-478b-a60c-3a1eac0c1ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (3.14.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from SpeechRecognition) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "febe2c54-b646-4fdd-bf80-e0ffed5fc4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb9ae72-0f6e-414e-bbbb-cc7fb36e1791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e83674f-38fd-4a7e-9a6a-0209696f6be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "import io\n",
    "import openai\n",
    "import anthropic\n",
    "import asyncio\n",
    "import re\n",
    "import pygame\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from gtts import gTTS\n",
    "from IPython.display import Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af4ff6a-7acf-4cb6-8d12-80fe7242a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Talker:\n",
    "    def __init__(self):\n",
    "        self.lang = 'ru'\n",
    "        self.queue = queue.Queue()\n",
    "        self.pattern = re.compile(r\"[.!?]+\")\n",
    "        self.buffer = ''\n",
    "        self.thread = threading.Thread(target=self._run_openai, daemon=True)\n",
    "        self.thread.start()\n",
    "\n",
    "    def _detect_language_by_first_letter(self, text):\n",
    "        first_char = text.strip()[0]\n",
    "        if 'А' <= first_char <= 'я' or first_char in 'Ёё':\n",
    "            self.lang = 'ru'\n",
    "        elif 'A' <= first_char <= 'Z' or 'a' <= first_char <= 'z':\n",
    "            self.lang = 'en'\n",
    "    \n",
    "    def play(self, text):\n",
    "        if text:\n",
    "            self._detect_language_by_first_letter(text)\n",
    "            self.buffer += text\n",
    "            parts = list(self.pattern.finditer(self.buffer))\n",
    "            \n",
    "            if len(parts) > 0:\n",
    "                ind = parts[-1].end()\n",
    "                self.queue.put(self.buffer[:ind])\n",
    "                self.buffer = self.buffer[ind:]\n",
    "                \n",
    "        elif self.buffer:\n",
    "            self.queue.put(self.buffer)\n",
    "\n",
    "    def _run_openai(self):\n",
    "        while True:\n",
    "            text = self.queue.get()\n",
    "            if text is None:\n",
    "                break;\n",
    "                \n",
    "            response = openai.audio.speech.create(\n",
    "                model=\"tts-1\",\n",
    "                voice=\"alloy\",\n",
    "                input=text\n",
    "            )\n",
    "        \n",
    "            audio_stream = BytesIO(response.content)\n",
    "            audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "            play(audio)\n",
    "    \n",
    "    def _run_gTTS(self):\n",
    "        pygame.mixer.init()\n",
    "        while True:\n",
    "            text = self.queue.get()\n",
    "            if text is None:\n",
    "                break  # For clean shutdown\n",
    "\n",
    "            # Generate TTS audio\n",
    "            tts = gTTS(text=text, lang=self.lang)\n",
    "            audio_buffer = io.BytesIO()\n",
    "            tts.write_to_fp(audio_buffer)\n",
    "            audio_buffer.seek(0)\n",
    "\n",
    "            # Play audio\n",
    "            pygame.mixer.music.load(audio_buffer)\n",
    "            pygame.mixer.music.play()\n",
    "\n",
    "            while pygame.mixer.music.get_busy():\n",
    "                pygame.time.wait(100)\n",
    "\n",
    "    def stop(self):\n",
    "        self.queue.put(None)\n",
    "        self.thread.join()\n",
    "\n",
    "talker = Talker()\n",
    "# talker.play('Расскажи-ка нам об индукции!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86993e99-3898-4519-90cd-126ccd4cb9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj\n",
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/ny/bjrptr9d4f9c3mmxj10zzcl40000gp/T/tmpec17akyq.wav':\n",
      "  Duration: 00:00:10.82, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "  10.70 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/ny/bjrptr9d4f9c3mmxj10zzcl40000gp/T/tmp7u1i8qh9.wav':\n",
      "  Duration: 00:00:09.02, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   8.92 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/ny/bjrptr9d4f9c3mmxj10zzcl40000gp/T/tmp283wbem2.wav':\n",
      "  Duration: 00:00:04.27, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   4.24 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def transcribe(audio, lang):\n",
    "    text = None\n",
    "    if audio:\n",
    "        try:\n",
    "            recognizer = sr.Recognizer()\n",
    "            with sr.AudioFile(audio) as source:\n",
    "                audio_data = recognizer.record(source)\n",
    "                text = recognizer.recognize_google(audio_data, language=lang)\n",
    "            print(text)\n",
    "        except Exception as e:\n",
    "            text = \"Sorry, failed to recognize\" if lang == 'en-US' else 'Извините, речь не распознана.'\n",
    "            print(e)\n",
    "            \n",
    "    return text or ''\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(openai_api_key[:7])\n",
    "else:\n",
    "    print('Failed to load OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "SYSTEM_MSG = 'Ты полезный технический помощник для инженеров. Ты даёшь чёткие краткие ответы. Если ты не знаешь ответ, то так и говоришь, что не знаешь.'\n",
    "\n",
    "gpt = openai.OpenAI()\n",
    "claude = anthropic.Anthropic()\n",
    "gemini = genai.Client(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "gemini_chat = gemini.chats.create(\n",
    "    model='gemini-2.5-flash',\n",
    "    config=types.GenerateContentConfig(system_instruction=SYSTEM_MSG)\n",
    ")\n",
    "deepseek = openai.OpenAI(api_key=os.getenv('DEEPSEEK_API_KEY'), base_url=\"https://api.deepseek.com\")\n",
    "ollama = openai.OpenAI(api_key='ollama', base_url=\"http://localhost:11434/v1\")\n",
    "\n",
    "\n",
    "def stream_gpt(history):\n",
    "    messages = [{'role': 'system', 'content': SYSTEM_MSG}]\n",
    "    messages += history\n",
    "    stream = gpt.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = ''\n",
    "    history += [{'role': 'assistant', 'content': result}]\n",
    "    for chunk in stream:\n",
    "        text = chunk.choices[0].delta.content\n",
    "        talker.play(text)\n",
    "        result += chunk.choices[0].delta.content or ''\n",
    "        history[-1] = {'role': 'assistant', 'content': result}\n",
    "        yield history\n",
    "\n",
    "\n",
    "def stream_claude(history):\n",
    "    response = claude.messages.stream(\n",
    "        model='claude-3-haiku-20240307',\n",
    "        max_tokens=500,\n",
    "        system=SYSTEM_MSG,\n",
    "        messages=history\n",
    "    )\n",
    "\n",
    "    result = ''\n",
    "    history += [{'role': 'assistant', 'content': result}]\n",
    "    with response as stream:\n",
    "        for text in stream.text_stream:\n",
    "            result += text or ''\n",
    "            talker.play(text)\n",
    "            history[-1] = {'role': 'assistant', 'content': result}\n",
    "            yield history\n",
    "\n",
    "\n",
    "def stream_gemini(history):\n",
    "    user_msg = history[-1]['content']\n",
    "    response = gemini_chat.send_message_stream(user_msg)\n",
    "    result = ''\n",
    "    history += [{'role': 'assistant', 'content': result}]\n",
    "\n",
    "    if len(gemini_chat.get_history()) > 0:\n",
    "        print(gemini_chat.get_history()[-1])\n",
    "    \n",
    "    for chunk in response:\n",
    "        result += chunk.text or ''\n",
    "        talker.play(chunk.text)\n",
    "        history[-1] = {'role': 'assistant', 'content': result}\n",
    "        yield history\n",
    "\n",
    "\n",
    "def stream_deepseek(history):\n",
    "    messages = [{'role': 'system', 'content': SYSTEM_MSG}]\n",
    "    messages += history\n",
    "    stream = deepseek.chat.completions.create(\n",
    "        model='deepseek-chat',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = ''\n",
    "    history += [{'role': 'assistant', 'content': result}]\n",
    "    for chunk in stream:\n",
    "        text = chunk.choices[0].delta.content\n",
    "        talker.play(text)\n",
    "        result += chunk.choices[0].delta.content or ''\n",
    "        history[-1] = {'role': 'assistant', 'content': result}\n",
    "        yield history\n",
    "\n",
    "\n",
    "def stream_ollama(history):\n",
    "    messages = [{'role': 'system', 'content': SYSTEM_MSG}]\n",
    "    messages += history\n",
    "    stream = ollama.chat.completions.create(\n",
    "        model='llama3.2',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = ''\n",
    "    history += [{'role': 'assistant', 'content': result}]\n",
    "    for chunk in stream:\n",
    "        text = chunk.choices[0].delta.content\n",
    "        talker.play(text)\n",
    "        result += chunk.choices[0].delta.content or ''\n",
    "        history[-1] = {'role': 'assistant', 'content': result}\n",
    "        yield history  \n",
    "        \n",
    "\n",
    "def ask_ai_model(model, history):\n",
    "    clean_history = [{'role': h['role'], 'content': h['content']} for h in history]\n",
    "\n",
    "    match model:\n",
    "        case 'gpt':\n",
    "            yield from stream_gpt(clean_history)\n",
    "        case 'Claude':\n",
    "            yield from stream_claude(clean_history)\n",
    "        case 'Gemini':\n",
    "            yield from stream_gemini(clean_history)\n",
    "        case 'Deepseek':\n",
    "            yield from stream_deepseek(clean_history)\n",
    "        case 'ollama':\n",
    "            yield from stream_ollama(clean_history)\n",
    "        case _:\n",
    "            text = f'{model}: not implemented yet.'\n",
    "            clean_history += [{'role': 'assistant', 'content': text}]\n",
    "            yield clean_history\n",
    "\n",
    "\n",
    "def entry_submit(message, history):\n",
    "    history += [{'role': 'user', 'content': message}]\n",
    "    return \"\", history\n",
    "\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(label=\"Chat\", height=300, type=\"messages\")\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant\", value=\"что такое фазовые конденсаторы\")\n",
    "        audio_entry = gr.Audio(label=\"Voice input\", sources=\"microphone\", type=\"filepath\")\n",
    "    with gr.Row():\n",
    "        model = gr.Dropdown(label = \"Choose a model\", value='gpt', choices=['gpt', 'Claude', 'Gemini', 'ollama', 'Deepseek'])\n",
    "        language = gr.Dropdown(label=\"Choose a language for speech recognition\", value='ru-RU', choices=['en-US', 'ru-RU'])\n",
    "    with gr.Row():\n",
    "        clear_button = gr.Button(\"Clear\")\n",
    "\n",
    "    entry.submit(entry_submit, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        ask_ai_model, inputs=[model, chatbot], outputs=[chatbot])\n",
    "    \n",
    "    audio_entry.input(transcribe, inputs=[audio_entry, language], outputs=[entry])\n",
    "    \n",
    "    clear_button.click(lambda: ('', \"\"), inputs=None, outputs=[entry, chatbot], queue=False)\n",
    "\n",
    "\n",
    "ui.launch(inbrowser=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235c8861-6de0-4cc0-bbe9-5351c8aeb6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
